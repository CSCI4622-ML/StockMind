{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataframe(df):\n",
    "    \"\"\"\n",
    "    Normalizes all columns in a pandas DataFrame  using MinMaxScaler.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The normalized DataFrame.\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    columns_to_normalize = [col for col in df.columns]\n",
    "    df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_up_column(df):\n",
    "    # Create empty 'up' and 'down' columns\n",
    "    df['up'] = np.nan\n",
    "    \n",
    "    # Loop over the rows (skipping the first row)\n",
    "    for i in range(0, len(df)-1):\n",
    "        if df.loc[i+1, '4. close'] > df.loc[i, '4. close']:\n",
    "            df.loc[i, 'up'] = 1\n",
    "        else:\n",
    "            df.loc[i, 'up'] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chaikin A/D</th>\n",
       "      <th>ADOSC</th>\n",
       "      <th>ADX</th>\n",
       "      <th>ADXR</th>\n",
       "      <th>APO</th>\n",
       "      <th>Aroon Down</th>\n",
       "      <th>Aroon Up</th>\n",
       "      <th>AROONOSC</th>\n",
       "      <th>ATR</th>\n",
       "      <th>Real Upper Band</th>\n",
       "      <th>...</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>company</th>\n",
       "      <th>up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8579</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.672490</td>\n",
       "      <td>0.258971</td>\n",
       "      <td>0.316359</td>\n",
       "      <td>0.754960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.302798</td>\n",
       "      <td>0.951020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929540</td>\n",
       "      <td>0.951991</td>\n",
       "      <td>0.944602</td>\n",
       "      <td>0.965739</td>\n",
       "      <td>0.140781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.766338</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8580</th>\n",
       "      <td>0.998778</td>\n",
       "      <td>0.664732</td>\n",
       "      <td>0.266415</td>\n",
       "      <td>0.306323</td>\n",
       "      <td>0.732013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.320301</td>\n",
       "      <td>0.943965</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.265542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.764780</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8581</th>\n",
       "      <td>0.966297</td>\n",
       "      <td>0.581039</td>\n",
       "      <td>0.254699</td>\n",
       "      <td>0.296031</td>\n",
       "      <td>0.687362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.365638</td>\n",
       "      <td>0.918791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936562</td>\n",
       "      <td>0.941350</td>\n",
       "      <td>0.893466</td>\n",
       "      <td>0.916730</td>\n",
       "      <td>0.157345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.755167</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8582</th>\n",
       "      <td>0.931217</td>\n",
       "      <td>0.468669</td>\n",
       "      <td>0.246950</td>\n",
       "      <td>0.288036</td>\n",
       "      <td>0.623677</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.462123</td>\n",
       "      <td>0.939905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855206</td>\n",
       "      <td>0.814194</td>\n",
       "      <td>0.785275</td>\n",
       "      <td>0.813039</td>\n",
       "      <td>0.264651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.502183</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8583</th>\n",
       "      <td>0.901446</td>\n",
       "      <td>0.365450</td>\n",
       "      <td>0.247488</td>\n",
       "      <td>0.285341</td>\n",
       "      <td>0.568705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.444907</td>\n",
       "      <td>0.964661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755206</td>\n",
       "      <td>0.776368</td>\n",
       "      <td>0.733902</td>\n",
       "      <td>0.763803</td>\n",
       "      <td>0.139751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415032</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Chaikin A/D     ADOSC       ADX      ADXR       APO  Aroon Down  \\\n",
       "8579     1.000000  0.672490  0.258971  0.316359  0.754960         0.0   \n",
       "8580     0.998778  0.664732  0.266415  0.306323  0.732013         0.0   \n",
       "8581     0.966297  0.581039  0.254699  0.296031  0.687362         0.0   \n",
       "8582     0.931217  0.468669  0.246950  0.288036  0.623677         1.0   \n",
       "8583     0.901446  0.365450  0.247488  0.285341  0.568705         1.0   \n",
       "\n",
       "      Aroon Up  AROONOSC       ATR  Real Upper Band  ...   2. high    3. low  \\\n",
       "8579      0.85     0.925  0.302798         0.951020  ...  0.929540  0.951991   \n",
       "8580      1.00     1.000  0.320301         0.943965  ...  1.000000  1.000000   \n",
       "8581      0.95     0.975  0.365638         0.918791  ...  0.936562  0.941350   \n",
       "8582      0.90     0.450  0.462123         0.939905  ...  0.855206  0.814194   \n",
       "8583      0.85     0.425  0.444907         0.964661  ...  0.755206  0.776368   \n",
       "\n",
       "      4. close  5. adjusted close  6. volume  7. dividend amount  \\\n",
       "8579  0.944602           0.965739   0.140781                 0.0   \n",
       "8580  0.980350           1.000000   0.265542                 0.0   \n",
       "8581  0.893466           0.916730   0.157345                 0.0   \n",
       "8582  0.785275           0.813039   0.264651                 0.0   \n",
       "8583  0.733902           0.763803   0.139751                 0.0   \n",
       "\n",
       "      8. split coefficient  sentiment  company   up  \n",
       "8579                   0.0   0.766338       28  1.0  \n",
       "8580                   0.0   0.764780       28  0.0  \n",
       "8581                   0.0   0.755167       28  0.0  \n",
       "8582                   0.0   0.502183       28  0.0  \n",
       "8583                   0.0   0.415032       28  NaN  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_csvs_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Combines all CSV files in a folder into a single pandas DataFrame also normalizes before combining them.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder containing the CSV files.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the concatenated data from all CSV files in the input folder.\n",
    "    \"\"\"\n",
    "    # Use a list comprehension to read all CSV files in the folder into a list of DataFrames.\n",
    "    dfs = [pd.read_csv(os.path.join(folder_path, f)) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    \n",
    "    # Use a list comprehension to get the filenames of all CSV files in the folder.\n",
    "    filenames = [os.path.splitext(os.path.basename(f))[0] for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "    processed_dfs = []\n",
    "    i = 0\n",
    "    for df, filename in zip(dfs, filenames):\n",
    "        # Dont need the date column\n",
    "        df = df.drop(['date'], axis=1)\n",
    "        # normalize the dataframes before combining them\n",
    "        df = normalize_dataframe(df)\n",
    "        # for the neural network to understand the company name we need to convert it to a number\n",
    "        df['company'] = i\n",
    "        i += 1\n",
    "        df = add_up_column(df)\n",
    "        processed_dfs.append(df)\n",
    "    combined_df = pd.concat(processed_dfs, ignore_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "df_full = combine_csvs_from_folder('market_data/merged_sentiment_data')\n",
    "\n",
    "df_full.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[295, 591, 887, 1183, 1479, 1775, 2071, 2367, 2663, 2959, 3255, 3551, 3847, 4143, 4439, 4735, 5031, 5327, 5623, 5919, 6215, 6511, 6807, 7103, 7399, 7695, 7991, 8287, 8583]\n"
     ]
    }
   ],
   "source": [
    "#we need this for later\n",
    "def find_indices_of_test_rows(df):\n",
    "    indices = []\n",
    "    for i in range(1, len(df)):\n",
    "        if np.isnan(df.loc[i, 'up']):\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "idxs = find_indices_of_test_rows(df_full)\n",
    "print(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should one hot encode the company column\n",
    "# first we need to change it to a string so we can one hot encode it\n",
    "df_full['company'] = df_full['company'].astype(str)\n",
    "df_full = pd.get_dummies(df_full, columns=['company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nan rows\n",
    "df_train = df_full.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chaikin A/D</th>\n",
       "      <th>ADOSC</th>\n",
       "      <th>ADX</th>\n",
       "      <th>ADXR</th>\n",
       "      <th>APO</th>\n",
       "      <th>Aroon Down</th>\n",
       "      <th>Aroon Up</th>\n",
       "      <th>AROONOSC</th>\n",
       "      <th>ATR</th>\n",
       "      <th>Real Upper Band</th>\n",
       "      <th>...</th>\n",
       "      <th>company_26</th>\n",
       "      <th>company_27</th>\n",
       "      <th>company_28</th>\n",
       "      <th>company_3</th>\n",
       "      <th>company_4</th>\n",
       "      <th>company_5</th>\n",
       "      <th>company_6</th>\n",
       "      <th>company_7</th>\n",
       "      <th>company_8</th>\n",
       "      <th>company_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.135312</td>\n",
       "      <td>0.619734</td>\n",
       "      <td>0.395503</td>\n",
       "      <td>0.459299</td>\n",
       "      <td>0.422455</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.603205</td>\n",
       "      <td>0.855696</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.161065</td>\n",
       "      <td>0.647807</td>\n",
       "      <td>0.407572</td>\n",
       "      <td>0.449526</td>\n",
       "      <td>0.400695</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.599784</td>\n",
       "      <td>0.843167</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.137926</td>\n",
       "      <td>0.582208</td>\n",
       "      <td>0.409131</td>\n",
       "      <td>0.430583</td>\n",
       "      <td>0.372748</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.577742</td>\n",
       "      <td>0.824053</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.121791</td>\n",
       "      <td>0.499820</td>\n",
       "      <td>0.424835</td>\n",
       "      <td>0.416918</td>\n",
       "      <td>0.317456</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.570574</td>\n",
       "      <td>0.816083</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.077162</td>\n",
       "      <td>0.354716</td>\n",
       "      <td>0.451172</td>\n",
       "      <td>0.410581</td>\n",
       "      <td>0.252092</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.596903</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8578</th>\n",
       "      <td>0.970065</td>\n",
       "      <td>0.646422</td>\n",
       "      <td>0.270488</td>\n",
       "      <td>0.335065</td>\n",
       "      <td>0.776503</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.320660</td>\n",
       "      <td>0.959564</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8579</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.672490</td>\n",
       "      <td>0.258971</td>\n",
       "      <td>0.316359</td>\n",
       "      <td>0.754960</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.302798</td>\n",
       "      <td>0.951020</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8580</th>\n",
       "      <td>0.998778</td>\n",
       "      <td>0.664732</td>\n",
       "      <td>0.266415</td>\n",
       "      <td>0.306323</td>\n",
       "      <td>0.732013</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.320301</td>\n",
       "      <td>0.943965</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8581</th>\n",
       "      <td>0.966297</td>\n",
       "      <td>0.581039</td>\n",
       "      <td>0.254699</td>\n",
       "      <td>0.296031</td>\n",
       "      <td>0.687362</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.365638</td>\n",
       "      <td>0.918791</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8582</th>\n",
       "      <td>0.931217</td>\n",
       "      <td>0.468669</td>\n",
       "      <td>0.246950</td>\n",
       "      <td>0.288036</td>\n",
       "      <td>0.623677</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.462123</td>\n",
       "      <td>0.939905</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8555 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Chaikin A/D     ADOSC       ADX      ADXR       APO  Aroon Down  \\\n",
       "0        0.135312  0.619734  0.395503  0.459299  0.422455        0.85   \n",
       "1        0.161065  0.647807  0.407572  0.449526  0.400695        0.80   \n",
       "2        0.137926  0.582208  0.409131  0.430583  0.372748        0.75   \n",
       "3        0.121791  0.499820  0.424835  0.416918  0.317456        0.70   \n",
       "4        0.077162  0.354716  0.451172  0.410581  0.252092        0.65   \n",
       "...           ...       ...       ...       ...       ...         ...   \n",
       "8578     0.970065  0.646422  0.270488  0.335065  0.776503        0.00   \n",
       "8579     1.000000  0.672490  0.258971  0.316359  0.754960        0.00   \n",
       "8580     0.998778  0.664732  0.266415  0.306323  0.732013        0.00   \n",
       "8581     0.966297  0.581039  0.254699  0.296031  0.687362        0.00   \n",
       "8582     0.931217  0.468669  0.246950  0.288036  0.623677        1.00   \n",
       "\n",
       "      Aroon Up  AROONOSC       ATR  Real Upper Band  ...  company_26  \\\n",
       "0         0.35     0.250  0.603205         0.855696  ...           0   \n",
       "1         0.30     0.250  0.599784         0.843167  ...           0   \n",
       "2         0.25     0.250  0.577742         0.824053  ...           0   \n",
       "3         0.20     0.250  0.570574         0.816083  ...           0   \n",
       "4         0.15     0.250  0.596903         0.814220  ...           0   \n",
       "...        ...       ...       ...              ...  ...         ...   \n",
       "8578      0.90     0.950  0.320660         0.959564  ...           0   \n",
       "8579      0.85     0.925  0.302798         0.951020  ...           0   \n",
       "8580      1.00     1.000  0.320301         0.943965  ...           0   \n",
       "8581      0.95     0.975  0.365638         0.918791  ...           0   \n",
       "8582      0.90     0.450  0.462123         0.939905  ...           0   \n",
       "\n",
       "      company_27  company_28  company_3  company_4  company_5  company_6  \\\n",
       "0              0           0          0          0          0          0   \n",
       "1              0           0          0          0          0          0   \n",
       "2              0           0          0          0          0          0   \n",
       "3              0           0          0          0          0          0   \n",
       "4              0           0          0          0          0          0   \n",
       "...          ...         ...        ...        ...        ...        ...   \n",
       "8578           0           1          0          0          0          0   \n",
       "8579           0           1          0          0          0          0   \n",
       "8580           0           1          0          0          0          0   \n",
       "8581           0           1          0          0          0          0   \n",
       "8582           0           1          0          0          0          0   \n",
       "\n",
       "      company_7  company_8  company_9  \n",
       "0             0          0          0  \n",
       "1             0          0          0  \n",
       "2             0          0          0  \n",
       "3             0          0          0  \n",
       "4             0          0          0  \n",
       "...         ...        ...        ...  \n",
       "8578          0          0          0  \n",
       "8579          0          0          0  \n",
       "8580          0          0          0  \n",
       "8581          0          0          0  \n",
       "8582          0          0          0  \n",
       "\n",
       "[8555 rows x 104 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master = df_train\n",
    "df_master"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_master.drop(columns=\"sentiment\")\n",
    "X_columns = [c for c in df.columns if c != \"up\"]\n",
    "y_column = \"up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df[X_columns].to_numpy()\n",
    "y_data = df[y_column].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(models, X, y):\n",
    "    \"\"\"\n",
    "    input: list(tuple(str, class)) models in the following format:\n",
    "        [(<name1>, <model1>), (<name2>, <model2>), ...]\n",
    "    output: list of tuples of name, trained model, and accuracy\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    names = []\n",
    "    trained_models = []\n",
    "    accuracies = []\n",
    "    for name, model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        names.append(name)\n",
    "        trained_models.append(model)\n",
    "        accuracies.append(acc)\n",
    "        print(f\"{name} got a training accuracy of {acc}\")\n",
    "\n",
    "    return [(a,b,c) for a,b,c in zip(names, trained_models, accuracies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad. Boost got a training accuracy of 0.578257790368272\n",
      "AdaBoost got a training accuracy of 0.5676345609065155\n",
      "Bagging got a training accuracy of 0.5545325779036827\n",
      "SVC got a training accuracy of 0.5446175637393768\n",
      "SGD got a training accuracy of 0.5010623229461756\n",
      "MLP got a training accuracy of 0.5516997167138811\n",
      "KNN got a training accuracy of 0.4936260623229462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\markr\\anaconda3\\envs\\stockmind_dev\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\markr\\anaconda3\\envs\\stockmind_dev\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\markr\\anaconda3\\envs\\stockmind_dev\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking got a training accuracy of 0.5796742209631728\n"
     ]
    }
   ],
   "source": [
    "xgb_model = GradientBoostingClassifier()\n",
    "ada_model = AdaBoostClassifier()\n",
    "bag_model = BaggingClassifier()\n",
    "svc_model = SVC()\n",
    "sgd_model = SGDClassifier()\n",
    "mlp_model = MLPClassifier(max_iter=500)\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "models = [(\"xgb\", GradientBoostingClassifier()),\n",
    "           (\"ada\", AdaBoostClassifier()), \n",
    "            (\"bag\", BaggingClassifier()), \n",
    "             (\"svc\", SVC()), \n",
    "              (\"sgd\", SGDClassifier()), \n",
    "               (\"mlp\", MLPClassifier(max_iter=500))]\n",
    "stc_model = StackingClassifier(models)\n",
    "\n",
    "test_models = [(\"Grad. Boost\", xgb_model),\n",
    "               (\"AdaBoost\", ada_model),\n",
    "               (\"Bagging\", bag_model),\n",
    "               (\"SVC\", svc_model),\n",
    "               (\"SGD\", sgd_model),\n",
    "               (\"MLP\", mlp_model),\n",
    "               (\"KNN\", knn_model),\n",
    "               (\"Stacking\", stc_model),\n",
    "               ]\n",
    "\n",
    "tech_train_results = train_test(test_models, X_data, y_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_master\n",
    "X_columns = [c for c in df.columns if c != \"up\"]\n",
    "y_column = \"up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df[X_columns].to_numpy()\n",
    "y_data = df[y_column].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad. Boost got a training accuracy of 0.5970254957507082\n",
      "AdaBoost got a training accuracy of 0.5828611898016998\n",
      "Bagging got a training accuracy of 0.5669263456090652\n",
      "SVC got a training accuracy of 0.5378895184135978\n",
      "SGD got a training accuracy of 0.5432011331444759\n",
      "MLP got a training accuracy of 0.5662181303116147\n",
      "KNN got a training accuracy of 0.4985835694050991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\markr\\anaconda3\\envs\\stockmind_dev\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\markr\\anaconda3\\envs\\stockmind_dev\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\markr\\anaconda3\\envs\\stockmind_dev\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\markr\\anaconda3\\envs\\stockmind_dev\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking got a training accuracy of 0.5938385269121813\n"
     ]
    }
   ],
   "source": [
    "xgb_model = GradientBoostingClassifier()\n",
    "ada_model = AdaBoostClassifier()\n",
    "bag_model = BaggingClassifier()\n",
    "svc_model = SVC()\n",
    "sgd_model = SGDClassifier()\n",
    "mlp_model = MLPClassifier(max_iter=500)\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "models = [(\"xgb\", GradientBoostingClassifier()),\n",
    "           (\"ada\", AdaBoostClassifier()), \n",
    "            (\"bag\", BaggingClassifier()), \n",
    "             (\"svc\", SVC()), \n",
    "              (\"sgd\", SGDClassifier()), \n",
    "               (\"mlp\", MLPClassifier(max_iter=500))]\n",
    "stc_model = StackingClassifier(models)\n",
    "\n",
    "test_models = [(\"Grad. Boost\", xgb_model),\n",
    "               (\"AdaBoost\", ada_model),\n",
    "               (\"Bagging\", bag_model),\n",
    "               (\"SVC\", svc_model),\n",
    "               (\"SGD\", sgd_model),\n",
    "               (\"MLP\", mlp_model),\n",
    "               (\"KNN\", knn_model),\n",
    "               (\"Stacking\", stc_model),\n",
    "               ]\n",
    "\n",
    "sentiment_train_results = train_test(test_models, X_data, y_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Sentiment Analysis Plus Additional Previous Day's news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\markr\\AppData\\Local\\Temp\\ipykernel_17784\\2580138920.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f\"sentiment_{i}\"] = df[\"sentiment\"].shift(i)\n",
      "C:\\Users\\markr\\AppData\\Local\\Temp\\ipykernel_17784\\2580138920.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f\"sentiment_{i}\"] = df[\"sentiment\"].shift(i)\n",
      "C:\\Users\\markr\\AppData\\Local\\Temp\\ipykernel_17784\\2580138920.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f\"sentiment_{i}\"] = df[\"sentiment\"].shift(i)\n",
      "C:\\Users\\markr\\AppData\\Local\\Temp\\ipykernel_17784\\2580138920.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f\"sentiment_{i}\"] = df[\"sentiment\"].shift(i)\n",
      "C:\\Users\\markr\\AppData\\Local\\Temp\\ipykernel_17784\\2580138920.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f\"sentiment_{i}\"] = df[\"sentiment\"].shift(i)\n",
      "C:\\Users\\markr\\AppData\\Local\\Temp\\ipykernel_17784\\2580138920.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f\"sentiment_{i}\"] = df[\"sentiment\"].shift(i)\n",
      "C:\\Users\\markr\\AppData\\Local\\Temp\\ipykernel_17784\\2580138920.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = df_master\n",
    "for i in range(1, 7):\n",
    "    df[f\"sentiment_{i}\"] = df[\"sentiment\"].shift(i)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = [c for c in df.columns if c != \"up\"]\n",
    "y_column = \"up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df[X_columns].to_numpy()\n",
    "y_data = df[y_column].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad. Boost got a training accuracy of 0.5861091424521616\n",
      "AdaBoost got a training accuracy of 0.5744153082919915\n",
      "Bagging got a training accuracy of 0.5609496810772502\n",
      "SVC got a training accuracy of 0.5379163713678242\n",
      "SGD got a training accuracy of 0.5223245924875974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\markr\\anaconda3\\envs\\stockmind_dev\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP got a training accuracy of 0.5513819985825655\n",
      "KNN got a training accuracy of 0.49751948972360027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\markr\\anaconda3\\envs\\stockmind_dev\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\markr\\anaconda3\\envs\\stockmind_dev\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\markr\\anaconda3\\envs\\stockmind_dev\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\markr\\anaconda3\\envs\\stockmind_dev\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking got a training accuracy of 0.5871722182849043\n"
     ]
    }
   ],
   "source": [
    "xgb_model = GradientBoostingClassifier()\n",
    "ada_model = AdaBoostClassifier()\n",
    "bag_model = BaggingClassifier()\n",
    "svc_model = SVC()\n",
    "sgd_model = SGDClassifier()\n",
    "mlp_model = MLPClassifier(max_iter=500)\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "models = [(\"xgb\", GradientBoostingClassifier()),\n",
    "           (\"ada\", AdaBoostClassifier()), \n",
    "            (\"bag\", BaggingClassifier()), \n",
    "             (\"svc\", SVC()), \n",
    "              (\"sgd\", SGDClassifier()), \n",
    "               (\"mlp\", MLPClassifier(max_iter=500))]\n",
    "stc_model = StackingClassifier(models)\n",
    "\n",
    "test_models = [(\"Grad. Boost\", xgb_model),\n",
    "               (\"AdaBoost\", ada_model),\n",
    "               (\"Bagging\", bag_model),\n",
    "               (\"SVC\", svc_model),\n",
    "               (\"SGD\", sgd_model),\n",
    "               (\"MLP\", mlp_model),\n",
    "               (\"KNN\", knn_model),\n",
    "               (\"Stacking\", stc_model),\n",
    "               ]\n",
    "\n",
    "sentiment_p_train_results = train_test(test_models, X_data, y_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chaikin A/D</th>\n",
       "      <th>ADOSC</th>\n",
       "      <th>ADX</th>\n",
       "      <th>ADXR</th>\n",
       "      <th>APO</th>\n",
       "      <th>Aroon Down</th>\n",
       "      <th>Aroon Up</th>\n",
       "      <th>AROONOSC</th>\n",
       "      <th>ATR</th>\n",
       "      <th>Real Upper Band</th>\n",
       "      <th>...</th>\n",
       "      <th>company_6</th>\n",
       "      <th>company_7</th>\n",
       "      <th>company_8</th>\n",
       "      <th>company_9</th>\n",
       "      <th>sentiment_1</th>\n",
       "      <th>sentiment_2</th>\n",
       "      <th>sentiment_3</th>\n",
       "      <th>sentiment_4</th>\n",
       "      <th>sentiment_5</th>\n",
       "      <th>sentiment_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.038411</td>\n",
       "      <td>0.177497</td>\n",
       "      <td>0.695121</td>\n",
       "      <td>0.465075</td>\n",
       "      <td>0.240003</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.703151</td>\n",
       "      <td>0.756102</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758145</td>\n",
       "      <td>0.898415</td>\n",
       "      <td>0.872104</td>\n",
       "      <td>0.821747</td>\n",
       "      <td>0.805998</td>\n",
       "      <td>0.743600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.082597</td>\n",
       "      <td>0.318983</td>\n",
       "      <td>0.704401</td>\n",
       "      <td>0.451961</td>\n",
       "      <td>0.240203</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.714965</td>\n",
       "      <td>0.723169</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.796698</td>\n",
       "      <td>0.758145</td>\n",
       "      <td>0.898415</td>\n",
       "      <td>0.872104</td>\n",
       "      <td>0.821747</td>\n",
       "      <td>0.805998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.112285</td>\n",
       "      <td>0.447096</td>\n",
       "      <td>0.707059</td>\n",
       "      <td>0.440916</td>\n",
       "      <td>0.259634</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.687340</td>\n",
       "      <td>0.686308</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.977138</td>\n",
       "      <td>0.796698</td>\n",
       "      <td>0.758145</td>\n",
       "      <td>0.898415</td>\n",
       "      <td>0.872104</td>\n",
       "      <td>0.821747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.161053</td>\n",
       "      <td>0.600500</td>\n",
       "      <td>0.689115</td>\n",
       "      <td>0.425413</td>\n",
       "      <td>0.274767</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.685287</td>\n",
       "      <td>0.669592</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.873524</td>\n",
       "      <td>0.977138</td>\n",
       "      <td>0.796698</td>\n",
       "      <td>0.758145</td>\n",
       "      <td>0.898415</td>\n",
       "      <td>0.872104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.179932</td>\n",
       "      <td>0.683870</td>\n",
       "      <td>0.661752</td>\n",
       "      <td>0.415688</td>\n",
       "      <td>0.285806</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.658527</td>\n",
       "      <td>0.662759</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.886805</td>\n",
       "      <td>0.873524</td>\n",
       "      <td>0.977138</td>\n",
       "      <td>0.796698</td>\n",
       "      <td>0.758145</td>\n",
       "      <td>0.898415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7818</th>\n",
       "      <td>0.970065</td>\n",
       "      <td>0.646422</td>\n",
       "      <td>0.270488</td>\n",
       "      <td>0.335065</td>\n",
       "      <td>0.776503</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.320660</td>\n",
       "      <td>0.959564</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.516550</td>\n",
       "      <td>0.739200</td>\n",
       "      <td>0.596341</td>\n",
       "      <td>0.616635</td>\n",
       "      <td>0.779338</td>\n",
       "      <td>0.664121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7819</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.672490</td>\n",
       "      <td>0.258971</td>\n",
       "      <td>0.316359</td>\n",
       "      <td>0.754960</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.302798</td>\n",
       "      <td>0.951020</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523149</td>\n",
       "      <td>0.516550</td>\n",
       "      <td>0.739200</td>\n",
       "      <td>0.596341</td>\n",
       "      <td>0.616635</td>\n",
       "      <td>0.779338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7820</th>\n",
       "      <td>0.998778</td>\n",
       "      <td>0.664732</td>\n",
       "      <td>0.266415</td>\n",
       "      <td>0.306323</td>\n",
       "      <td>0.732013</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.320301</td>\n",
       "      <td>0.943965</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.766338</td>\n",
       "      <td>0.523149</td>\n",
       "      <td>0.516550</td>\n",
       "      <td>0.739200</td>\n",
       "      <td>0.596341</td>\n",
       "      <td>0.616635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7821</th>\n",
       "      <td>0.966297</td>\n",
       "      <td>0.581039</td>\n",
       "      <td>0.254699</td>\n",
       "      <td>0.296031</td>\n",
       "      <td>0.687362</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.365638</td>\n",
       "      <td>0.918791</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.764780</td>\n",
       "      <td>0.766338</td>\n",
       "      <td>0.523149</td>\n",
       "      <td>0.516550</td>\n",
       "      <td>0.739200</td>\n",
       "      <td>0.596341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7822</th>\n",
       "      <td>0.931217</td>\n",
       "      <td>0.468669</td>\n",
       "      <td>0.246950</td>\n",
       "      <td>0.288036</td>\n",
       "      <td>0.623677</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.462123</td>\n",
       "      <td>0.939905</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.755167</td>\n",
       "      <td>0.764780</td>\n",
       "      <td>0.766338</td>\n",
       "      <td>0.523149</td>\n",
       "      <td>0.516550</td>\n",
       "      <td>0.739200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7785 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Chaikin A/D     ADOSC       ADX      ADXR       APO  Aroon Down  \\\n",
       "10       0.038411  0.177497  0.695121  0.465075  0.240003        0.95   \n",
       "11       0.082597  0.318983  0.704401  0.451961  0.240203        0.90   \n",
       "12       0.112285  0.447096  0.707059  0.440916  0.259634        0.85   \n",
       "13       0.161053  0.600500  0.689115  0.425413  0.274767        0.80   \n",
       "14       0.179932  0.683870  0.661752  0.415688  0.285806        0.75   \n",
       "...           ...       ...       ...       ...       ...         ...   \n",
       "7818     0.970065  0.646422  0.270488  0.335065  0.776503        0.00   \n",
       "7819     1.000000  0.672490  0.258971  0.316359  0.754960        0.00   \n",
       "7820     0.998778  0.664732  0.266415  0.306323  0.732013        0.00   \n",
       "7821     0.966297  0.581039  0.254699  0.296031  0.687362        0.00   \n",
       "7822     0.931217  0.468669  0.246950  0.288036  0.623677        1.00   \n",
       "\n",
       "      Aroon Up  AROONOSC       ATR  Real Upper Band  ...  company_6  \\\n",
       "10        0.10     0.075  0.703151         0.756102  ...          0   \n",
       "11        0.05     0.075  0.714965         0.723169  ...          0   \n",
       "12        0.00     0.075  0.687340         0.686308  ...          0   \n",
       "13        0.00     0.100  0.685287         0.669592  ...          0   \n",
       "14        0.00     0.125  0.658527         0.662759  ...          0   \n",
       "...        ...       ...       ...              ...  ...        ...   \n",
       "7818      0.90     0.950  0.320660         0.959564  ...          0   \n",
       "7819      0.85     0.925  0.302798         0.951020  ...          0   \n",
       "7820      1.00     1.000  0.320301         0.943965  ...          0   \n",
       "7821      0.95     0.975  0.365638         0.918791  ...          0   \n",
       "7822      0.90     0.450  0.462123         0.939905  ...          0   \n",
       "\n",
       "      company_7  company_8  company_9  sentiment_1  sentiment_2  sentiment_3  \\\n",
       "10            0          0          0     0.758145     0.898415     0.872104   \n",
       "11            0          0          0     0.796698     0.758145     0.898415   \n",
       "12            0          0          0     0.977138     0.796698     0.758145   \n",
       "13            0          0          0     0.873524     0.977138     0.796698   \n",
       "14            0          0          0     0.886805     0.873524     0.977138   \n",
       "...         ...        ...        ...          ...          ...          ...   \n",
       "7818          0          0          0     0.516550     0.739200     0.596341   \n",
       "7819          0          0          0     0.523149     0.516550     0.739200   \n",
       "7820          0          0          0     0.766338     0.523149     0.516550   \n",
       "7821          0          0          0     0.764780     0.766338     0.523149   \n",
       "7822          0          0          0     0.755167     0.764780     0.766338   \n",
       "\n",
       "      sentiment_4  sentiment_5  sentiment_6  \n",
       "10       0.821747     0.805998     0.743600  \n",
       "11       0.872104     0.821747     0.805998  \n",
       "12       0.898415     0.872104     0.821747  \n",
       "13       0.758145     0.898415     0.872104  \n",
       "14       0.796698     0.758145     0.898415  \n",
       "...           ...          ...          ...  \n",
       "7818     0.616635     0.779338     0.664121  \n",
       "7819     0.596341     0.616635     0.779338  \n",
       "7820     0.739200     0.596341     0.616635  \n",
       "7821     0.516550     0.739200     0.596341  \n",
       "7822     0.523149     0.516550     0.739200  \n",
       "\n",
       "[7785 rows x 110 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tomorrow_dfs = [pd.read_csv(os.path.join(folder_path, f)) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    for tom_df, filename in zip(tomorrow_dfs, filenames):\n",
    "        \n",
    "        df = df.drop(['date'], axis=1)\n",
    "        # normalize the dataframes before combining them\n",
    "        df = normalize_dataframe(df)\n",
    "        # for the neural network to understand the company name we need to convert it to a number\n",
    "        df['company'] = i\n",
    "        i += 1\n",
    "        df = add_up_column(df)\n",
    "        processed_dfs.append(df)\n",
    "    combined_df = pd.concat(processed_dfs, ignore_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "df_full = combine_csvs_from_folder('market_data/merged_sentiment_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5115218154170078"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_data, np.zeros(y_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stockmind_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
