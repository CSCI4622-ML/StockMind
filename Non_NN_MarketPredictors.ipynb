{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataframe(df):\n",
    "    \"\"\"\n",
    "    Normalizes all columns in a pandas DataFrame  using MinMaxScaler.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The normalized DataFrame.\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    columns_to_normalize = [col for col in df.columns]\n",
    "    df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_up_column(df):\n",
    "    # Create empty 'up' and 'down' columns\n",
    "    df['up'] = np.nan\n",
    "    \n",
    "    # Loop over the rows (skipping the first row)\n",
    "    for i in range(0, len(df)-1):\n",
    "        if df.loc[i+1, '4. close'] > df.loc[i, '4. close']:\n",
    "            df.loc[i, 'up'] = 1\n",
    "        else:\n",
    "            df.loc[i, 'up'] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chaikin A/D</th>\n",
       "      <th>ADOSC</th>\n",
       "      <th>ADX</th>\n",
       "      <th>ADXR</th>\n",
       "      <th>APO</th>\n",
       "      <th>Aroon Down</th>\n",
       "      <th>Aroon Up</th>\n",
       "      <th>AROONOSC</th>\n",
       "      <th>ATR</th>\n",
       "      <th>Real Upper Band</th>\n",
       "      <th>...</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>company</th>\n",
       "      <th>up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8579</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.672490</td>\n",
       "      <td>0.258971</td>\n",
       "      <td>0.316359</td>\n",
       "      <td>0.754960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.302798</td>\n",
       "      <td>0.951020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929540</td>\n",
       "      <td>0.951991</td>\n",
       "      <td>0.944602</td>\n",
       "      <td>0.965739</td>\n",
       "      <td>0.140781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.766338</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8580</th>\n",
       "      <td>0.998778</td>\n",
       "      <td>0.664732</td>\n",
       "      <td>0.266415</td>\n",
       "      <td>0.306323</td>\n",
       "      <td>0.732013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.320301</td>\n",
       "      <td>0.943965</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.265542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.764780</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8581</th>\n",
       "      <td>0.966297</td>\n",
       "      <td>0.581039</td>\n",
       "      <td>0.254699</td>\n",
       "      <td>0.296031</td>\n",
       "      <td>0.687362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.365638</td>\n",
       "      <td>0.918791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936562</td>\n",
       "      <td>0.941350</td>\n",
       "      <td>0.893466</td>\n",
       "      <td>0.916730</td>\n",
       "      <td>0.157345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.755167</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8582</th>\n",
       "      <td>0.931217</td>\n",
       "      <td>0.468669</td>\n",
       "      <td>0.246950</td>\n",
       "      <td>0.288036</td>\n",
       "      <td>0.623677</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.462123</td>\n",
       "      <td>0.939905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855206</td>\n",
       "      <td>0.814194</td>\n",
       "      <td>0.785275</td>\n",
       "      <td>0.813039</td>\n",
       "      <td>0.264651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.502183</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8583</th>\n",
       "      <td>0.901446</td>\n",
       "      <td>0.365450</td>\n",
       "      <td>0.247488</td>\n",
       "      <td>0.285341</td>\n",
       "      <td>0.568705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.444907</td>\n",
       "      <td>0.964661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755206</td>\n",
       "      <td>0.776368</td>\n",
       "      <td>0.733902</td>\n",
       "      <td>0.763803</td>\n",
       "      <td>0.139751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415032</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Chaikin A/D     ADOSC       ADX      ADXR       APO  Aroon Down  \\\n",
       "8579     1.000000  0.672490  0.258971  0.316359  0.754960         0.0   \n",
       "8580     0.998778  0.664732  0.266415  0.306323  0.732013         0.0   \n",
       "8581     0.966297  0.581039  0.254699  0.296031  0.687362         0.0   \n",
       "8582     0.931217  0.468669  0.246950  0.288036  0.623677         1.0   \n",
       "8583     0.901446  0.365450  0.247488  0.285341  0.568705         1.0   \n",
       "\n",
       "      Aroon Up  AROONOSC       ATR  Real Upper Band  ...   2. high    3. low  \\\n",
       "8579      0.85     0.925  0.302798         0.951020  ...  0.929540  0.951991   \n",
       "8580      1.00     1.000  0.320301         0.943965  ...  1.000000  1.000000   \n",
       "8581      0.95     0.975  0.365638         0.918791  ...  0.936562  0.941350   \n",
       "8582      0.90     0.450  0.462123         0.939905  ...  0.855206  0.814194   \n",
       "8583      0.85     0.425  0.444907         0.964661  ...  0.755206  0.776368   \n",
       "\n",
       "      4. close  5. adjusted close  6. volume  7. dividend amount  \\\n",
       "8579  0.944602           0.965739   0.140781                 0.0   \n",
       "8580  0.980350           1.000000   0.265542                 0.0   \n",
       "8581  0.893466           0.916730   0.157345                 0.0   \n",
       "8582  0.785275           0.813039   0.264651                 0.0   \n",
       "8583  0.733902           0.763803   0.139751                 0.0   \n",
       "\n",
       "      8. split coefficient  sentiment  company   up  \n",
       "8579                   0.0   0.766338       28  1.0  \n",
       "8580                   0.0   0.764780       28  0.0  \n",
       "8581                   0.0   0.755167       28  0.0  \n",
       "8582                   0.0   0.502183       28  0.0  \n",
       "8583                   0.0   0.415032       28  NaN  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_csvs_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Combines all CSV files in a folder into a single pandas DataFrame also normalizes before combining them.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder containing the CSV files.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the concatenated data from all CSV files in the input folder.\n",
    "    \"\"\"\n",
    "    # Use a list comprehension to read all CSV files in the folder into a list of DataFrames.\n",
    "    dfs = [pd.read_csv(os.path.join(folder_path, f)) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    \n",
    "    # Use a list comprehension to get the filenames of all CSV files in the folder.\n",
    "    filenames = [os.path.splitext(os.path.basename(f))[0] for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "    processed_dfs = []\n",
    "    i = 0\n",
    "    for df, filename in zip(dfs, filenames):\n",
    "        # Dont need the date column\n",
    "        df = df.drop(['date'], axis=1)\n",
    "        # normalize the dataframes before combining them\n",
    "        df = normalize_dataframe(df)\n",
    "        # for the neural network to understand the company name we need to convert it to a number\n",
    "        df['company'] = i\n",
    "        i += 1\n",
    "        df = add_up_column(df)\n",
    "        processed_dfs.append(df)\n",
    "    combined_df = pd.concat(processed_dfs, ignore_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "df_full = combine_csvs_from_folder('market_data/merged_sentiment_data')\n",
    "\n",
    "df_full.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[295, 591, 887, 1183, 1479, 1775, 2071, 2367, 2663, 2959, 3255, 3551, 3847, 4143, 4439, 4735, 5031, 5327, 5623, 5919, 6215, 6511, 6807, 7103, 7399, 7695, 7991, 8287, 8583]\n"
     ]
    }
   ],
   "source": [
    "#we need this for later\n",
    "def find_indices_of_test_rows(df):\n",
    "    indices = []\n",
    "    for i in range(1, len(df)):\n",
    "        if np.isnan(df.loc[i, 'up']):\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "idxs = find_indices_of_test_rows(df_full)\n",
    "print(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should one hot encode the company column\n",
    "# first we need to change it to a string so we can one hot encode it\n",
    "df_full['company'] = df_full['company'].astype(str)\n",
    "df_full = pd.get_dummies(df_full, columns=['company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nan rows\n",
    "df_train = df_full.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chaikin A/D</th>\n",
       "      <th>ADOSC</th>\n",
       "      <th>ADX</th>\n",
       "      <th>ADXR</th>\n",
       "      <th>APO</th>\n",
       "      <th>Aroon Down</th>\n",
       "      <th>Aroon Up</th>\n",
       "      <th>AROONOSC</th>\n",
       "      <th>ATR</th>\n",
       "      <th>Real Upper Band</th>\n",
       "      <th>...</th>\n",
       "      <th>company_26</th>\n",
       "      <th>company_27</th>\n",
       "      <th>company_28</th>\n",
       "      <th>company_3</th>\n",
       "      <th>company_4</th>\n",
       "      <th>company_5</th>\n",
       "      <th>company_6</th>\n",
       "      <th>company_7</th>\n",
       "      <th>company_8</th>\n",
       "      <th>company_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.135312</td>\n",
       "      <td>0.619734</td>\n",
       "      <td>0.395503</td>\n",
       "      <td>0.459299</td>\n",
       "      <td>0.422455</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.603205</td>\n",
       "      <td>0.855696</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.161065</td>\n",
       "      <td>0.647807</td>\n",
       "      <td>0.407572</td>\n",
       "      <td>0.449526</td>\n",
       "      <td>0.400695</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.599784</td>\n",
       "      <td>0.843167</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.137926</td>\n",
       "      <td>0.582208</td>\n",
       "      <td>0.409131</td>\n",
       "      <td>0.430583</td>\n",
       "      <td>0.372748</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.577742</td>\n",
       "      <td>0.824053</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.121791</td>\n",
       "      <td>0.499820</td>\n",
       "      <td>0.424835</td>\n",
       "      <td>0.416918</td>\n",
       "      <td>0.317456</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.570574</td>\n",
       "      <td>0.816083</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.077162</td>\n",
       "      <td>0.354716</td>\n",
       "      <td>0.451172</td>\n",
       "      <td>0.410581</td>\n",
       "      <td>0.252092</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.596903</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8578</th>\n",
       "      <td>0.970065</td>\n",
       "      <td>0.646422</td>\n",
       "      <td>0.270488</td>\n",
       "      <td>0.335065</td>\n",
       "      <td>0.776503</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.320660</td>\n",
       "      <td>0.959564</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8579</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.672490</td>\n",
       "      <td>0.258971</td>\n",
       "      <td>0.316359</td>\n",
       "      <td>0.754960</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.302798</td>\n",
       "      <td>0.951020</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8580</th>\n",
       "      <td>0.998778</td>\n",
       "      <td>0.664732</td>\n",
       "      <td>0.266415</td>\n",
       "      <td>0.306323</td>\n",
       "      <td>0.732013</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.320301</td>\n",
       "      <td>0.943965</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8581</th>\n",
       "      <td>0.966297</td>\n",
       "      <td>0.581039</td>\n",
       "      <td>0.254699</td>\n",
       "      <td>0.296031</td>\n",
       "      <td>0.687362</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.365638</td>\n",
       "      <td>0.918791</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8582</th>\n",
       "      <td>0.931217</td>\n",
       "      <td>0.468669</td>\n",
       "      <td>0.246950</td>\n",
       "      <td>0.288036</td>\n",
       "      <td>0.623677</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.462123</td>\n",
       "      <td>0.939905</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8555 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Chaikin A/D     ADOSC       ADX      ADXR       APO  Aroon Down  \\\n",
       "0        0.135312  0.619734  0.395503  0.459299  0.422455        0.85   \n",
       "1        0.161065  0.647807  0.407572  0.449526  0.400695        0.80   \n",
       "2        0.137926  0.582208  0.409131  0.430583  0.372748        0.75   \n",
       "3        0.121791  0.499820  0.424835  0.416918  0.317456        0.70   \n",
       "4        0.077162  0.354716  0.451172  0.410581  0.252092        0.65   \n",
       "...           ...       ...       ...       ...       ...         ...   \n",
       "8578     0.970065  0.646422  0.270488  0.335065  0.776503        0.00   \n",
       "8579     1.000000  0.672490  0.258971  0.316359  0.754960        0.00   \n",
       "8580     0.998778  0.664732  0.266415  0.306323  0.732013        0.00   \n",
       "8581     0.966297  0.581039  0.254699  0.296031  0.687362        0.00   \n",
       "8582     0.931217  0.468669  0.246950  0.288036  0.623677        1.00   \n",
       "\n",
       "      Aroon Up  AROONOSC       ATR  Real Upper Band  ...  company_26  \\\n",
       "0         0.35     0.250  0.603205         0.855696  ...           0   \n",
       "1         0.30     0.250  0.599784         0.843167  ...           0   \n",
       "2         0.25     0.250  0.577742         0.824053  ...           0   \n",
       "3         0.20     0.250  0.570574         0.816083  ...           0   \n",
       "4         0.15     0.250  0.596903         0.814220  ...           0   \n",
       "...        ...       ...       ...              ...  ...         ...   \n",
       "8578      0.90     0.950  0.320660         0.959564  ...           0   \n",
       "8579      0.85     0.925  0.302798         0.951020  ...           0   \n",
       "8580      1.00     1.000  0.320301         0.943965  ...           0   \n",
       "8581      0.95     0.975  0.365638         0.918791  ...           0   \n",
       "8582      0.90     0.450  0.462123         0.939905  ...           0   \n",
       "\n",
       "      company_27  company_28  company_3  company_4  company_5  company_6  \\\n",
       "0              0           0          0          0          0          0   \n",
       "1              0           0          0          0          0          0   \n",
       "2              0           0          0          0          0          0   \n",
       "3              0           0          0          0          0          0   \n",
       "4              0           0          0          0          0          0   \n",
       "...          ...         ...        ...        ...        ...        ...   \n",
       "8578           0           1          0          0          0          0   \n",
       "8579           0           1          0          0          0          0   \n",
       "8580           0           1          0          0          0          0   \n",
       "8581           0           1          0          0          0          0   \n",
       "8582           0           1          0          0          0          0   \n",
       "\n",
       "      company_7  company_8  company_9  \n",
       "0             0          0          0  \n",
       "1             0          0          0  \n",
       "2             0          0          0  \n",
       "3             0          0          0  \n",
       "4             0          0          0  \n",
       "...         ...        ...        ...  \n",
       "8578          0          0          0  \n",
       "8579          0          0          0  \n",
       "8580          0          0          0  \n",
       "8581          0          0          0  \n",
       "8582          0          0          0  \n",
       "\n",
       "[8555 rows x 104 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master = df_train\n",
    "df_master"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_master.drop(columns=\"sentiment\").copy()\n",
    "X_columns = [c for c in df.columns if c != \"up\"]\n",
    "y_column = \"up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df[X_columns].to_numpy()\n",
    "y_data = df[y_column].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(models, X, y):\n",
    "    \"\"\"\n",
    "    input: list(tuple(str, class)) models in the following format:\n",
    "        [(<name1>, <model1>), (<name2>, <model2>), ...]\n",
    "    output: list of tuples of name, trained model, and accuracy\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    names = []\n",
    "    trained_models = []\n",
    "    accuracies = []\n",
    "    for name, model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc_test = accuracy_score(y_test, y_pred)\n",
    "        acc_train = accuracy_score(y_train, model.predict(X_train))\n",
    "\n",
    "        names.append(name)\n",
    "        trained_models.append(model)\n",
    "        accuracies.append(acc_test)\n",
    "        print(f\"{name} got a train acc of {acc_train} and a test acc of {acc_test}\")\n",
    "\n",
    "    return [(a,b,c) for a,b,c in zip(names, trained_models, accuracies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad. Boost got a train acc of 0.7086023381608795 and a test acc of 0.580028328611898\n",
      "AdaBoost got a train acc of 0.6290350724131915 and a test acc of 0.5601983002832861\n",
      "Bagging got a train acc of 0.9853428720991101 and a test acc of 0.5470963172804533\n",
      "SVC got a train acc of 0.6389809806316524 and a test acc of 0.5435552407932012\n",
      "SGD got a train acc of 0.5534810678764613 and a test acc of 0.5276203966005666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP got a train acc of 0.8689582969813296 and a test acc of 0.5601983002832861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking got a train acc of 0.9164194730413541 and a test acc of 0.5892351274787535\n"
     ]
    }
   ],
   "source": [
    "xgb_model = GradientBoostingClassifier()\n",
    "ada_model = AdaBoostClassifier()\n",
    "bag_model = BaggingClassifier()\n",
    "svc_model = SVC()\n",
    "sgd_model = SGDClassifier()\n",
    "mlp_model = MLPClassifier(max_iter=500)\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "models = [(\"xgb\", GradientBoostingClassifier()),\n",
    "           (\"ada\", AdaBoostClassifier()), \n",
    "            (\"bag\", BaggingClassifier()), \n",
    "             (\"svc\", SVC()), \n",
    "              (\"sgd\", SGDClassifier()), \n",
    "               (\"mlp\", MLPClassifier(max_iter=500))]\n",
    "stc_model = StackingClassifier(models)\n",
    "\n",
    "test_models = [(\"Grad. Boost\", xgb_model),\n",
    "               (\"AdaBoost\", ada_model),\n",
    "               (\"Bagging\", bag_model),\n",
    "               (\"SVC\", svc_model),\n",
    "               (\"SGD\", sgd_model),\n",
    "               (\"MLP\", mlp_model),\n",
    "               #(\"KNN\", knn_model),\n",
    "               (\"Stacking\", stc_model)\n",
    "               ]\n",
    "\n",
    "tech_train_results = train_test(test_models, X_data, y_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_master.copy()\n",
    "X_columns = [c for c in df.columns if c != \"up\"]\n",
    "y_column = \"up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df[X_columns].to_numpy()\n",
    "y_data = df[y_column].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad. Boost got a train acc of 0.7044145873320538 and a test acc of 0.5881728045325779\n",
      "AdaBoost got a train acc of 0.6234514046414238 and a test acc of 0.5626770538243626\n",
      "Bagging got a train acc of 0.9848194032455069 and a test acc of 0.5506373937677054\n",
      "SVC got a train acc of 0.6344442505670913 and a test acc of 0.5347025495750708\n",
      "SGD got a train acc of 0.5564473913802129 and a test acc of 0.5460339943342776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP got a train acc of 0.8816960390856744 and a test acc of 0.5524079320113314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking got a train acc of 0.860059326470075 and a test acc of 0.5828611898016998\n"
     ]
    }
   ],
   "source": [
    "xgb_model = GradientBoostingClassifier()\n",
    "ada_model = AdaBoostClassifier()\n",
    "bag_model = BaggingClassifier()\n",
    "svc_model = SVC()\n",
    "sgd_model = SGDClassifier()\n",
    "mlp_model = MLPClassifier(max_iter=500)\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "models = [(\"xgb\", GradientBoostingClassifier()),\n",
    "           (\"ada\", AdaBoostClassifier()), \n",
    "            (\"bag\", BaggingClassifier()), \n",
    "             (\"svc\", SVC()), \n",
    "              (\"sgd\", SGDClassifier()), \n",
    "               (\"mlp\", MLPClassifier(max_iter=500))]\n",
    "stc_model = StackingClassifier(models)\n",
    "\n",
    "test_models = [(\"Grad. Boost\", xgb_model),\n",
    "               (\"AdaBoost\", ada_model),\n",
    "               (\"Bagging\", bag_model),\n",
    "               (\"SVC\", svc_model),\n",
    "               (\"SGD\", sgd_model),\n",
    "               (\"MLP\", mlp_model),\n",
    "               #(\"KNN\", knn_model),\n",
    "               (\"Stacking\", stc_model),\n",
    "               ]\n",
    "\n",
    "sentiment_train_results = train_test(test_models, X_data, y_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Sentiment Analysis Plus Additional Previous Day's news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_master.copy()\n",
    "for i in range(1, 7):\n",
    "    df[f\"sentiment_{i}\"] = df[\"sentiment\"].shift(i)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = [c for c in df.columns if c != \"up\"]\n",
    "y_column = \"up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df[X_columns].to_numpy()\n",
    "y_data = df[y_column].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad. Boost got a train acc of 0.7246376811594203 and a test acc of 0.5744153082919915\n",
      "AdaBoost got a train acc of 0.6280775275013096 and a test acc of 0.5655563430191354\n",
      "Bagging got a train acc of 0.9830626855247075 and a test acc of 0.5712260807937632\n",
      "SVC got a train acc of 0.6403003317618299 and a test acc of 0.5460666194188519\n",
      "SGD got a train acc of 0.5763925266282521 and a test acc of 0.5439404677533664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP got a train acc of 0.8894709271870089 and a test acc of 0.5744153082919915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking got a train acc of 0.9032652348524532 and a test acc of 0.5889440113394756\n"
     ]
    }
   ],
   "source": [
    "xgb_model = GradientBoostingClassifier()\n",
    "ada_model = AdaBoostClassifier()\n",
    "bag_model = BaggingClassifier()\n",
    "svc_model = SVC()\n",
    "sgd_model = SGDClassifier()\n",
    "mlp_model = MLPClassifier(max_iter=500)\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "models = [(\"xgb\", GradientBoostingClassifier()),\n",
    "           (\"ada\", AdaBoostClassifier()), \n",
    "            (\"bag\", BaggingClassifier()), \n",
    "             (\"svc\", SVC()), \n",
    "              (\"sgd\", SGDClassifier()), \n",
    "               (\"mlp\", MLPClassifier(max_iter=500))]\n",
    "stc_model = StackingClassifier(models)\n",
    "\n",
    "test_models = [(\"Grad. Boost\", xgb_model),\n",
    "               (\"AdaBoost\", ada_model),\n",
    "               (\"Bagging\", bag_model),\n",
    "               (\"SVC\", svc_model),\n",
    "               (\"SGD\", sgd_model),\n",
    "               (\"MLP\", mlp_model),\n",
    "               #(\"KNN\", knn_model),\n",
    "               (\"Stacking\", stc_model),\n",
    "               ]\n",
    "\n",
    "sentiment_p_train_results = train_test(test_models, X_data, y_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tomorrow_dfs = [pd.read_csv(os.path.join(folder_path, f)) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "#     for tom_df, filename in zip(tomorrow_dfs, filenames):\n",
    "        \n",
    "#         df = df.drop(['date'], axis=1)\n",
    "#         # normalize the dataframes before combining them\n",
    "#         df = normalize_dataframe(df)\n",
    "#         # for the neural network to understand the company name we need to convert it to a number\n",
    "#         df['company'] = i\n",
    "#         i += 1\n",
    "#         df = add_up_column(df)\n",
    "#         processed_dfs.append(df)\n",
    "#     combined_df = pd.concat(processed_dfs, ignore_index=True)\n",
    "    \n",
    "#     return combined_df\n",
    "\n",
    "# df_full = combine_csvs_from_folder('market_data/merged_sentiment_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_master.copy()\n",
    "X_columns = [c for c in df.columns if c != \"up\"]\n",
    "y_column = \"up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df[X_columns].to_numpy()\n",
    "y_data = df[y_column].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL: 0.0\n",
      "ADBE: 1.0\n",
      "AFRM: 1.0\n",
      "AMD: 0.0\n",
      "AMZN: 1.0\n",
      "AVGO: 0.0\n",
      "BAC: 1.0\n",
      "BIO: 1.0\n",
      "BKNG: 0.0\n",
      "COIN: 1.0\n",
      "DKNG: 1.0\n",
      "GOOG: 1.0\n",
      "JPM: 0.0\n",
      "KO: 0.0\n",
      "MA: 0.0\n",
      "META: 0.0\n",
      "MSFT: 0.0\n",
      "NVDA: 0.0\n",
      "OPEN: 1.0\n",
      "PG: 0.0\n",
      "PLUG: 1.0\n",
      "RDFN: 1.0\n",
      "SHOP: 1.0\n",
      "SQ: 1.0\n",
      "TEAM: 1.0\n",
      "TSLA: 1.0\n",
      "UNH: 0.0\n",
      "WMT: 0.0\n",
      "XOM: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_df = df_full[df_full.isna().any(axis=1)]\n",
    "test_df = test_df.drop(['up'], axis=1)\n",
    "xgb_model = GradientBoostingClassifier()\n",
    "xgb_model.fit(X_data, y_data)\n",
    "y_pred = xgb_model.predict(test_df.to_numpy())\n",
    "filenames = [os.path.splitext(os.path.basename(f))[0] for f in os.listdir(\"market_data/merged_sentiment_data\") if f.endswith('.csv')]\n",
    "for filename, pred in zip(filenames, y_pred):\n",
    "    print(f\"{filename}: {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5115218154170078"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_data, np.zeros(y_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stockmind_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
