{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataframe(df):\n",
    "    \"\"\"\n",
    "    Normalizes all columns in a pandas DataFrame  using MinMaxScaler.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The normalized DataFrame.\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    columns_to_normalize = [col for col in df.columns]\n",
    "    df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chaikin A/D</th>\n",
       "      <th>ADOSC</th>\n",
       "      <th>ADX</th>\n",
       "      <th>ADXR</th>\n",
       "      <th>APO</th>\n",
       "      <th>Aroon Down</th>\n",
       "      <th>Aroon Up</th>\n",
       "      <th>AROONOSC</th>\n",
       "      <th>ATR</th>\n",
       "      <th>Real Upper Band</th>\n",
       "      <th>...</th>\n",
       "      <th>WMA</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54006</th>\n",
       "      <td>0.828590</td>\n",
       "      <td>0.611121</td>\n",
       "      <td>0.124368</td>\n",
       "      <td>0.161278</td>\n",
       "      <td>0.721455</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.371731</td>\n",
       "      <td>0.908468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912402</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.792715</td>\n",
       "      <td>0.795367</td>\n",
       "      <td>0.785348</td>\n",
       "      <td>0.915660</td>\n",
       "      <td>0.053093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54007</th>\n",
       "      <td>0.831386</td>\n",
       "      <td>0.613370</td>\n",
       "      <td>0.120646</td>\n",
       "      <td>0.147684</td>\n",
       "      <td>0.739753</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.361116</td>\n",
       "      <td>0.912497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915420</td>\n",
       "      <td>0.780175</td>\n",
       "      <td>0.785976</td>\n",
       "      <td>0.794163</td>\n",
       "      <td>0.787510</td>\n",
       "      <td>0.917801</td>\n",
       "      <td>0.047816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54008</th>\n",
       "      <td>0.832392</td>\n",
       "      <td>0.613550</td>\n",
       "      <td>0.109766</td>\n",
       "      <td>0.139020</td>\n",
       "      <td>0.741281</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.358681</td>\n",
       "      <td>0.914832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917420</td>\n",
       "      <td>0.777547</td>\n",
       "      <td>0.778555</td>\n",
       "      <td>0.786126</td>\n",
       "      <td>0.778268</td>\n",
       "      <td>0.908648</td>\n",
       "      <td>0.041491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54009</th>\n",
       "      <td>0.836382</td>\n",
       "      <td>0.618820</td>\n",
       "      <td>0.098034</td>\n",
       "      <td>0.135600</td>\n",
       "      <td>0.750070</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.349887</td>\n",
       "      <td>0.916590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919478</td>\n",
       "      <td>0.775004</td>\n",
       "      <td>0.777489</td>\n",
       "      <td>0.784578</td>\n",
       "      <td>0.780133</td>\n",
       "      <td>0.910496</td>\n",
       "      <td>0.049474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54010</th>\n",
       "      <td>0.838405</td>\n",
       "      <td>0.621768</td>\n",
       "      <td>0.096450</td>\n",
       "      <td>0.133156</td>\n",
       "      <td>0.760952</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.345329</td>\n",
       "      <td>0.918329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922155</td>\n",
       "      <td>0.781107</td>\n",
       "      <td>0.788834</td>\n",
       "      <td>0.792659</td>\n",
       "      <td>0.788697</td>\n",
       "      <td>0.918977</td>\n",
       "      <td>0.044220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Chaikin A/D     ADOSC       ADX      ADXR       APO  Aroon Down  \\\n",
       "54006     0.828590  0.611121  0.124368  0.161278  0.721455        0.35   \n",
       "54007     0.831386  0.613370  0.120646  0.147684  0.739753        0.30   \n",
       "54008     0.832392  0.613550  0.109766  0.139020  0.741281        0.25   \n",
       "54009     0.836382  0.618820  0.098034  0.135600  0.750070        0.20   \n",
       "54010     0.838405  0.621768  0.096450  0.133156  0.760952        0.15   \n",
       "\n",
       "       Aroon Up  AROONOSC       ATR  Real Upper Band  ...       WMA   1. open  \\\n",
       "54006      1.00     0.825  0.371731         0.908468  ...  0.912402  0.789583   \n",
       "54007      0.95     0.825  0.361116         0.912497  ...  0.915420  0.780175   \n",
       "54008      0.90     0.825  0.358681         0.914832  ...  0.917420  0.777547   \n",
       "54009      0.85     0.825  0.349887         0.916590  ...  0.919478  0.775004   \n",
       "54010      0.80     0.825  0.345329         0.918329  ...  0.922155  0.781107   \n",
       "\n",
       "        2. high    3. low  4. close  5. adjusted close  6. volume  \\\n",
       "54006  0.792715  0.795367  0.785348           0.915660   0.053093   \n",
       "54007  0.785976  0.794163  0.787510           0.917801   0.047816   \n",
       "54008  0.778555  0.786126  0.778268           0.908648   0.041491   \n",
       "54009  0.777489  0.784578  0.780133           0.910496   0.049474   \n",
       "54010  0.788834  0.792659  0.788697           0.918977   0.044220   \n",
       "\n",
       "       7. dividend amount  8. split coefficient  company  \n",
       "54006                 0.0                   0.0       10  \n",
       "54007                 0.0                   0.0       10  \n",
       "54008                 0.0                   0.0       10  \n",
       "54009                 0.0                   0.0       10  \n",
       "54010                 0.0                   0.0       10  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_csvs_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Combines all CSV files in a folder into a single pandas DataFrame also normalizes before combining them.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder containing the CSV files.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the concatenated data from all CSV files in the input folder.\n",
    "    \"\"\"\n",
    "    # Use a list comprehension to read all CSV files in the folder into a list of DataFrames.\n",
    "    dfs = [pd.read_csv(os.path.join(folder_path, f)) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    \n",
    "    # Use a list comprehension to get the filenames of all CSV files in the folder.\n",
    "    filenames = [os.path.splitext(os.path.basename(f))[0] for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "    processed_dfs = []\n",
    "    i = 0\n",
    "    for df, filename in zip(dfs, filenames):\n",
    "        # Dont need the date column\n",
    "        df = df.drop(['date'], axis=1)\n",
    "        # normalize the dataframes before combining them\n",
    "        df = normalize_dataframe(df)\n",
    "        # for the neural network to understand the company name we need to convert it to a number\n",
    "        df['company'] = i\n",
    "        i += 1\n",
    "        processed_dfs.append(df)\n",
    "    combined_df = pd.concat(processed_dfs, ignore_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "df = combine_csvs_from_folder('market_data/merged_data')\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need this for later\n",
    "def find_indices_of_last_company_changes(df):\n",
    "    indices = []\n",
    "    for i in range(1, len(df)):\n",
    "        if df.loc[i, 'company'] != df.loc[i - 1, 'company']:\n",
    "            indices.append(i-1)\n",
    "    return indices\n",
    "idxs = find_indices_of_last_company_changes(df)\n",
    "idxs.append(len(df) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should one hot encode the company column\n",
    "# first we need to change it to a string so we can one hot encode it\n",
    "df['company'] = df['company'].astype(str)\n",
    "df = pd.get_dummies(df, columns=['company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chaikin A/D</th>\n",
       "      <th>ADOSC</th>\n",
       "      <th>ADX</th>\n",
       "      <th>ADXR</th>\n",
       "      <th>APO</th>\n",
       "      <th>Aroon Down</th>\n",
       "      <th>Aroon Up</th>\n",
       "      <th>AROONOSC</th>\n",
       "      <th>ATR</th>\n",
       "      <th>Real Upper Band</th>\n",
       "      <th>...</th>\n",
       "      <th>company_10</th>\n",
       "      <th>company_2</th>\n",
       "      <th>company_3</th>\n",
       "      <th>company_4</th>\n",
       "      <th>company_5</th>\n",
       "      <th>company_6</th>\n",
       "      <th>company_7</th>\n",
       "      <th>company_8</th>\n",
       "      <th>company_9</th>\n",
       "      <th>up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.172135</td>\n",
       "      <td>0.545425</td>\n",
       "      <td>0.154470</td>\n",
       "      <td>0.101243</td>\n",
       "      <td>0.502764</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.010778</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.169640</td>\n",
       "      <td>0.532056</td>\n",
       "      <td>0.164471</td>\n",
       "      <td>0.106557</td>\n",
       "      <td>0.502062</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.010778</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.173826</td>\n",
       "      <td>0.555077</td>\n",
       "      <td>0.164130</td>\n",
       "      <td>0.114041</td>\n",
       "      <td>0.502022</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.011184</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.177859</td>\n",
       "      <td>0.590061</td>\n",
       "      <td>0.159311</td>\n",
       "      <td>0.123042</td>\n",
       "      <td>0.501608</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.011078</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.173893</td>\n",
       "      <td>0.583195</td>\n",
       "      <td>0.149749</td>\n",
       "      <td>0.131813</td>\n",
       "      <td>0.501044</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.011167</td>\n",
       "      <td>0.004806</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Chaikin A/D     ADOSC       ADX      ADXR       APO  Aroon Down  Aroon Up  \\\n",
       "0     0.172135  0.545425  0.154470  0.101243  0.502764        0.95      0.25   \n",
       "1     0.169640  0.532056  0.164471  0.106557  0.502062        0.90      0.20   \n",
       "2     0.173826  0.555077  0.164130  0.114041  0.502022        0.85      0.15   \n",
       "3     0.177859  0.590061  0.159311  0.123042  0.501608        0.80      0.10   \n",
       "4     0.173893  0.583195  0.149749  0.131813  0.501044        0.75      0.05   \n",
       "\n",
       "   AROONOSC       ATR  Real Upper Band  ...  company_10  company_2  company_3  \\\n",
       "0      0.15  0.010778         0.004883  ...           0          0          0   \n",
       "1      0.15  0.010778         0.004920  ...           0          0          0   \n",
       "2      0.15  0.011184         0.004920  ...           0          0          0   \n",
       "3      0.15  0.011078         0.004897  ...           0          0          0   \n",
       "4      0.15  0.011167         0.004806  ...           0          0          0   \n",
       "\n",
       "   company_4  company_5  company_6  company_7  company_8  company_9  up  \n",
       "0          0          0          0          0          0          0   0  \n",
       "1          0          0          0          0          0          0   0  \n",
       "2          0          0          0          0          0          0   1  \n",
       "3          0          0          0          0          0          0   1  \n",
       "4          0          0          0          0          0          0   0  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_up_column(df):\n",
    "    # Create empty 'up' and 'down' columns\n",
    "    df['up'] = 0\n",
    "    \n",
    "    # Loop over the rows (skipping the first row)\n",
    "    for i in range(1, len(df)):\n",
    "        if df.loc[i, '4. close'] > df.loc[i-1, '4. close']:\n",
    "            df.loc[i, 'up'] = 1\n",
    "    return df\n",
    "\n",
    "\n",
    "df = add_up_column(df)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1721, 0.5454, 0.1545, 0.1012, 0.5028, 0.9500, 0.2500, 0.1500, 0.0108,\n",
      "        0.0049, 0.0044, 0.0048, 0.6001, 0.3041, 0.3204, 0.0041, 0.3287, 0.0043,\n",
      "        0.0770, 0.1221, 0.4935, 0.5869, 0.4913, 0.8474, 0.0045, 1.0000, 0.0041,\n",
      "        0.4687, 0.4572, 0.5075, 0.5028, 0.4830, 0.5257, 0.0021, 0.0000, 0.4928,\n",
      "        0.0043, 0.0044, 0.4145, 0.0082, 0.4762, 0.3511, 0.2082, 0.1884, 0.0058,\n",
      "        0.7284, 0.5345, 0.5344, 0.3204, 0.0051, 0.0044, 0.1780, 0.2642, 0.3207,\n",
      "        0.1780, 0.2269, 0.0756, 0.0045, 0.0039, 0.0067, 0.0046, 0.7760, 0.3548,\n",
      "        0.1964, 0.0043, 0.1429, 0.1544, 0.1394, 0.1461, 0.0037, 0.0121, 0.0000,\n",
      "        0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000])\n",
      "torch.Size([54011, 84])\n",
      "torch.Size([54011, 1])\n"
     ]
    }
   ],
   "source": [
    "# neural networks require tensors, so we need to convert our dataframes to tensors\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    inputs_columns = df.columns[df.columns != 'up']\n",
    "    inputs = torch.from_numpy(df.loc[:, inputs_columns].values.astype('float32'))\n",
    "    targets = torch.from_numpy(df.loc[:, ['up']].values.astype('float32'))\n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "inputs, targets = df_to_tensor(df)\n",
    "print(inputs[0])\n",
    "print(inputs.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(inputs, targets, seq_length):\n",
    "    seq_inputs = []\n",
    "    seq_targets = []\n",
    "    for i in range(len(inputs) - seq_length):\n",
    "        seq_inputs.append(inputs[i:i + seq_length])\n",
    "        seq_targets.append(targets[i + seq_length])\n",
    "    return torch.stack(seq_inputs), torch.stack(seq_targets)\n",
    "\n",
    "sequence_length = 10\n",
    "seq_inputs, seq_targets  = create_sequences(inputs, targets, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a training and validation dataset\n",
    "\n",
    "dataset = TensorDataset(seq_inputs, seq_targets)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch uses dataloaders to load data in batches\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(dataset, batch_size, shuffle = True, num_workers = 0)\n",
    "val_loader = DataLoader(val_dataset, 1, shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# use gpu if avaliable\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_NN(\n",
       "  (lstm): LSTM(84, 256, num_layers=5, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTM_NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# input size is 84 because we have 84 columns in our dataframe\n",
    "# output size is 1 because we are predicting up=1 or down=0\n",
    "input_size = 84\n",
    "output_size = 1\n",
    "hidden_size = 256\n",
    "num_layers = 5\n",
    "model = LSTM_NN(input_size, hidden_size, num_layers, output_size)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for training\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, avg_loss: 0.6928862305049083\n",
      "epoch: 10, avg_loss: 0.6924643126709201\n",
      "epoch: 20, avg_loss: 0.6898251531813382\n",
      "epoch: 30, avg_loss: 0.678598887829984\n",
      "epoch: 40, avg_loss: 0.6362416151010595\n",
      "epoch: 50, avg_loss: 0.5247650896485948\n",
      "epoch: 60, avg_loss: 0.3572774843017072\n",
      "epoch: 70, avg_loss: 0.2046513776361095\n",
      "epoch: 80, avg_loss: 0.10956209705551088\n",
      "epoch: 90, avg_loss: 0.05832555910387028\n",
      "epoch: 100, avg_loss: 0.04781207407855592\n",
      "epoch: 110, avg_loss: 0.03816635207100926\n",
      "epoch: 120, avg_loss: 0.02868058370488091\n",
      "epoch: 130, avg_loss: 0.028203790312218015\n",
      "epoch: 140, avg_loss: 0.025467800156884247\n",
      "epoch: 150, avg_loss: 0.022579576547579812\n",
      "epoch: 160, avg_loss: 0.02593912668217203\n",
      "epoch: 170, avg_loss: 0.022861866047605872\n",
      "epoch: 180, avg_loss: 0.021153714597198708\n",
      "epoch: 190, avg_loss: 0.019293662436500686\n",
      "epoch: 200, avg_loss: 0.022224639913164326\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "training_losses = []\n",
    "sequence_length = 10\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    epoch_loss = 0\n",
    "    for batch in train_loader:\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.view(-1, sequence_length, input_size)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # forward pass\n",
    "        outputs = model(inputs)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    #average the loss over all batches\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    training_losses.append(avg_loss)\n",
    "    if(epoch % 10 == 0 or epoch == 1):\n",
    "        print(f'epoch: {epoch}, avg_loss: {avg_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.]], device='cuda:0')\n",
      "tensor([[1.]], device='cuda:0')\n",
      "val_loss: 0.016557812549495104, val_acc: 0.5203221923895935\n"
     ]
    }
   ],
   "source": [
    "def validate(model, dataloader, criterion):\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    flag = 0\n",
    "    \n",
    "    with torch.no_grad(): # Disable gradient calculation for efficiency\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.view(-1, sequence_length, input_size)\n",
    "            inputs, targets = inputs.to(device), targets.to(device) # Move data to GPU if available\n",
    "            outputs = model(inputs)\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            loss = criterion(outputs, targets.float()) # BCE loss expects float inputs\n",
    "            val_loss += loss.item() * inputs.size(0) # Track total validation loss\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            if flag == 0:\n",
    "                print(targets)\n",
    "                print(torch.round(torch.sigmoid(outputs)))\n",
    "                flag = 1\n",
    "            predicted = torch.round(torch.sigmoid(outputs))\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    \n",
    "    # Calculate average validation loss and accuracy\n",
    "    val_loss /= len(dataloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    return val_loss, accuracy\n",
    "\n",
    "val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "print(f'val_loss: {val_loss}, val_acc: {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8384, 0.6218, 0.0964, 0.1332, 0.7610, 0.1500, 0.8000, 0.8250, 0.3453,\n",
      "        0.9183, 0.9200, 0.9199, 0.7466, 0.7152, 0.5881, 0.9176, 0.1422, 0.9272,\n",
      "        0.1510, 0.6481, 0.4280, 0.4814, 0.4289, 0.0998, 0.9250, 1.0000, 0.9338,\n",
      "        0.7940, 0.7269, 0.6243, 0.7610, 0.7181, 0.5339, 0.9604, 0.9982, 0.7262,\n",
      "        0.9215, 0.9080, 0.3292, 0.2287, 0.7729, 0.0916, 0.9254, 0.4240, 0.3633,\n",
      "        0.5953, 0.5943, 0.5943, 0.5881, 0.8577, 0.9200, 0.5049, 0.5539, 0.7208,\n",
      "        0.5049, 0.8912, 0.3345, 0.9084, 0.9210, 0.1042, 0.9145, 0.6438, 0.7618,\n",
      "        0.9248, 0.9222, 0.7811, 0.7888, 0.7927, 0.7887, 0.9190, 0.0442, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000], device='cuda:0')\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "LSTM: Expected input to be 2-D or 3-D but received 1-D tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(inputs[\u001b[39mlen\u001b[39m(inputs)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m----> 7\u001b[0m model(inputs[\u001b[39mlen\u001b[39;49m(inputs)\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\peter\\anaconda3\\envs\\alpaca\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m, in \u001b[0;36mLSTM_NN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m h0 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size)\u001b[39m.\u001b[39mto(x\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m     11\u001b[0m c0 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size)\u001b[39m.\u001b[39mto(x\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m---> 12\u001b[0m out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x, (h0, c0))\n\u001b[0;32m     13\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(out[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :])\n\u001b[0;32m     14\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\peter\\anaconda3\\envs\\alpaca\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\peter\\anaconda3\\envs\\alpaca\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:773\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    771\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    772\u001b[0m     batch_sizes \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 773\u001b[0m     \u001b[39massert\u001b[39;00m (\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLSTM: Expected input to be 2-D or 3-D but received \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39m-D tensor\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    774\u001b[0m     is_batched \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m    775\u001b[0m     batch_dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: LSTM: Expected input to be 2-D or 3-D but received 1-D tensor"
     ]
    }
   ],
   "source": [
    "#not yet working for LSTM model\n",
    "\n",
    "# how will visa do tomorrow? > 0.5 = up, < 0.5 = down\n",
    "inputs, targets = df_to_tensor(df)\n",
    "inputs = inputs.to(device)\n",
    "print(inputs[len(inputs)-1])\n",
    "model(inputs[len(inputs)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [os.path.splitext(os.path.basename(f))[0] for f in os.listdir(\"market_data/merged_data/\") if f.endswith('.csv')]\n",
    "\n",
    "for i, idx in enumerate(idxs):\n",
    "    print(f\"{filenames[i]}: {model(inputs[idx]).item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
