{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataframe(df):\n",
    "    \"\"\"\n",
    "    Normalizes all columns in a pandas DataFrame  using MinMaxScaler.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The normalized DataFrame.\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    columns_to_normalize = [col for col in df.columns]\n",
    "    df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chaikin A/D</th>\n",
       "      <th>ADOSC</th>\n",
       "      <th>ADX</th>\n",
       "      <th>ADXR</th>\n",
       "      <th>APO</th>\n",
       "      <th>Aroon Down</th>\n",
       "      <th>Aroon Up</th>\n",
       "      <th>AROONOSC</th>\n",
       "      <th>ATR</th>\n",
       "      <th>Real Upper Band</th>\n",
       "      <th>...</th>\n",
       "      <th>WMA</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43059</th>\n",
       "      <td>0.925470</td>\n",
       "      <td>0.543459</td>\n",
       "      <td>0.271353</td>\n",
       "      <td>0.215465</td>\n",
       "      <td>0.558804</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.512792</td>\n",
       "      <td>0.961274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937124</td>\n",
       "      <td>0.717283</td>\n",
       "      <td>0.724516</td>\n",
       "      <td>0.725372</td>\n",
       "      <td>0.724509</td>\n",
       "      <td>0.984667</td>\n",
       "      <td>0.085269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43060</th>\n",
       "      <td>0.924521</td>\n",
       "      <td>0.546146</td>\n",
       "      <td>0.280797</td>\n",
       "      <td>0.216888</td>\n",
       "      <td>0.602606</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.498271</td>\n",
       "      <td>0.970419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945408</td>\n",
       "      <td>0.718257</td>\n",
       "      <td>0.725454</td>\n",
       "      <td>0.730207</td>\n",
       "      <td>0.721923</td>\n",
       "      <td>0.981716</td>\n",
       "      <td>0.054010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43061</th>\n",
       "      <td>0.920910</td>\n",
       "      <td>0.543406</td>\n",
       "      <td>0.278851</td>\n",
       "      <td>0.211492</td>\n",
       "      <td>0.651815</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.497862</td>\n",
       "      <td>0.976177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951449</td>\n",
       "      <td>0.715121</td>\n",
       "      <td>0.718033</td>\n",
       "      <td>0.710737</td>\n",
       "      <td>0.703099</td>\n",
       "      <td>0.961788</td>\n",
       "      <td>0.077614</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43062</th>\n",
       "      <td>0.924132</td>\n",
       "      <td>0.552326</td>\n",
       "      <td>0.277001</td>\n",
       "      <td>0.212026</td>\n",
       "      <td>0.734318</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.490675</td>\n",
       "      <td>0.983225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958346</td>\n",
       "      <td>0.708679</td>\n",
       "      <td>0.712659</td>\n",
       "      <td>0.711424</td>\n",
       "      <td>0.712511</td>\n",
       "      <td>0.972543</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43063</th>\n",
       "      <td>0.919373</td>\n",
       "      <td>0.549282</td>\n",
       "      <td>0.282166</td>\n",
       "      <td>0.216814</td>\n",
       "      <td>0.813328</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.486867</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966062</td>\n",
       "      <td>0.728429</td>\n",
       "      <td>0.728909</td>\n",
       "      <td>0.730895</td>\n",
       "      <td>0.721923</td>\n",
       "      <td>0.983297</td>\n",
       "      <td>0.134807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Chaikin A/D     ADOSC       ADX      ADXR       APO  Aroon Down  \\\n",
       "43059     0.925470  0.543459  0.271353  0.215465  0.558804        0.65   \n",
       "43060     0.924521  0.546146  0.280797  0.216888  0.602606        0.60   \n",
       "43061     0.920910  0.543406  0.278851  0.211492  0.651815        0.55   \n",
       "43062     0.924132  0.552326  0.277001  0.212026  0.734318        0.50   \n",
       "43063     0.919373  0.549282  0.282166  0.216814  0.813328        0.45   \n",
       "\n",
       "       Aroon Up  AROONOSC       ATR  Real Upper Band  ...       WMA   1. open  \\\n",
       "43059      0.95      0.65  0.512792         0.961274  ...  0.937124  0.717283   \n",
       "43060      0.90      0.65  0.498271         0.970419  ...  0.945408  0.718257   \n",
       "43061      0.85      0.65  0.497862         0.976177  ...  0.951449  0.715121   \n",
       "43062      0.80      0.65  0.490675         0.983225  ...  0.958346  0.708679   \n",
       "43063      0.75      0.65  0.486867         0.992715  ...  0.966062  0.728429   \n",
       "\n",
       "        2. high    3. low  4. close  5. adjusted close  6. volume  \\\n",
       "43059  0.724516  0.725372  0.724509           0.984667   0.085269   \n",
       "43060  0.725454  0.730207  0.721923           0.981716   0.054010   \n",
       "43061  0.718033  0.710737  0.703099           0.961788   0.077614   \n",
       "43062  0.712659  0.711424  0.712511           0.972543   0.066541   \n",
       "43063  0.728909  0.730895  0.721923           0.983297   0.134807   \n",
       "\n",
       "       7. dividend amount  8. split coefficient  company  \n",
       "43059            0.000000                   0.0       10  \n",
       "43060            0.000000                   0.0       10  \n",
       "43061            0.666667                   0.0       10  \n",
       "43062            0.000000                   0.0       10  \n",
       "43063            0.000000                   0.0       10  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_csvs_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Combines all CSV files in a folder into a single pandas DataFrame also normalizes before combining them.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder containing the CSV files.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the concatenated data from all CSV files in the input folder.\n",
    "    \"\"\"\n",
    "    # Use a list comprehension to read all CSV files in the folder into a list of DataFrames.\n",
    "    dfs = [pd.read_csv(os.path.join(folder_path, f)) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    \n",
    "    # Use a list comprehension to get the filenames of all CSV files in the folder.\n",
    "    filenames = [os.path.splitext(os.path.basename(f))[0] for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "    processed_dfs = []\n",
    "    i = 0\n",
    "    for df, filename in zip(dfs, filenames):\n",
    "        # Dont need the date column\n",
    "        df = df.drop(['date'], axis=1)\n",
    "        # normalize the dataframes before combining them\n",
    "        df = normalize_dataframe(df)\n",
    "        # for the neural network to understand the company name we need to convert it to a number\n",
    "        df['company'] = i\n",
    "        i += 1\n",
    "        processed_dfs.append(df)\n",
    "    combined_df = pd.concat(processed_dfs, ignore_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "df = combine_csvs_from_folder('market_data/merged_data')\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need this for later\n",
    "def find_indices_of_last_company_changes(df):\n",
    "    indices = []\n",
    "    for i in range(1, len(df)):\n",
    "        if df.loc[i, 'company'] != df.loc[i - 1, 'company']:\n",
    "            indices.append(i-1)\n",
    "    return indices\n",
    "idxs = find_indices_of_last_company_changes(df)\n",
    "idxs.append(len(df) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should one hot encode the company column\n",
    "# first we need to change it to a string so we can one hot encode it\n",
    "df['company'] = df['company'].astype(str)\n",
    "df = pd.get_dummies(df, columns=['company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chaikin A/D</th>\n",
       "      <th>ADOSC</th>\n",
       "      <th>ADX</th>\n",
       "      <th>ADXR</th>\n",
       "      <th>APO</th>\n",
       "      <th>Aroon Down</th>\n",
       "      <th>Aroon Up</th>\n",
       "      <th>AROONOSC</th>\n",
       "      <th>ATR</th>\n",
       "      <th>Real Upper Band</th>\n",
       "      <th>...</th>\n",
       "      <th>company_10</th>\n",
       "      <th>company_2</th>\n",
       "      <th>company_3</th>\n",
       "      <th>company_4</th>\n",
       "      <th>company_5</th>\n",
       "      <th>company_6</th>\n",
       "      <th>company_7</th>\n",
       "      <th>company_8</th>\n",
       "      <th>company_9</th>\n",
       "      <th>up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.176768</td>\n",
       "      <td>0.545425</td>\n",
       "      <td>0.154470</td>\n",
       "      <td>0.101243</td>\n",
       "      <td>0.431009</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.061018</td>\n",
       "      <td>0.017387</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.174206</td>\n",
       "      <td>0.532056</td>\n",
       "      <td>0.164471</td>\n",
       "      <td>0.106557</td>\n",
       "      <td>0.427970</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.061018</td>\n",
       "      <td>0.017519</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.178504</td>\n",
       "      <td>0.555077</td>\n",
       "      <td>0.164130</td>\n",
       "      <td>0.114041</td>\n",
       "      <td>0.427821</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.063319</td>\n",
       "      <td>0.017517</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.182646</td>\n",
       "      <td>0.590061</td>\n",
       "      <td>0.159311</td>\n",
       "      <td>0.123042</td>\n",
       "      <td>0.426002</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.062719</td>\n",
       "      <td>0.017436</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.178573</td>\n",
       "      <td>0.583195</td>\n",
       "      <td>0.149749</td>\n",
       "      <td>0.131813</td>\n",
       "      <td>0.423586</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.063219</td>\n",
       "      <td>0.017113</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Chaikin A/D     ADOSC       ADX      ADXR       APO  Aroon Down  Aroon Up  \\\n",
       "0     0.176768  0.545425  0.154470  0.101243  0.431009        0.95      0.25   \n",
       "1     0.174206  0.532056  0.164471  0.106557  0.427970        0.90      0.20   \n",
       "2     0.178504  0.555077  0.164130  0.114041  0.427821        0.85      0.15   \n",
       "3     0.182646  0.590061  0.159311  0.123042  0.426002        0.80      0.10   \n",
       "4     0.178573  0.583195  0.149749  0.131813  0.423586        0.75      0.05   \n",
       "\n",
       "   AROONOSC       ATR  Real Upper Band  ...  company_10  company_2  company_3  \\\n",
       "0      0.15  0.061018         0.017387  ...           0          0          0   \n",
       "1      0.15  0.061018         0.017519  ...           0          0          0   \n",
       "2      0.15  0.063319         0.017517  ...           0          0          0   \n",
       "3      0.15  0.062719         0.017436  ...           0          0          0   \n",
       "4      0.15  0.063219         0.017113  ...           0          0          0   \n",
       "\n",
       "   company_4  company_5  company_6  company_7  company_8  company_9  up  \n",
       "0          0          0          0          0          0          0   0  \n",
       "1          0          0          0          0          0          0   0  \n",
       "2          0          0          0          0          0          0   1  \n",
       "3          0          0          0          0          0          0   1  \n",
       "4          0          0          0          0          0          0   0  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_up_column(df):\n",
    "    # Create empty 'up' and 'down' columns\n",
    "    df['up'] = 0\n",
    "    \n",
    "    # Loop over the rows (skipping the first row)\n",
    "    for i in range(1, len(df)):\n",
    "        if df.loc[i, '4. close'] > df.loc[i-1, '4. close']:\n",
    "            df.loc[i, 'up'] = 1\n",
    "    return df\n",
    "\n",
    "\n",
    "df = add_up_column(df)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1768, 0.5454, 0.1545, 0.1012, 0.4310, 0.9500, 0.2500, 0.1500, 0.0610,\n",
      "        0.0174, 0.0162, 0.0184, 0.6001, 0.3041, 0.3204, 0.0149, 0.3287, 0.0154,\n",
      "        0.0770, 0.1221, 0.3806, 0.3714, 0.4913, 0.8474, 0.0167, 1.0000, 0.0145,\n",
      "        0.4291, 0.4456, 0.4205, 0.4310, 0.4336, 0.3848, 0.0077, 0.0000, 0.4928,\n",
      "        0.0158, 0.0159, 0.4145, 0.0368, 0.4311, 0.3511, 0.2082, 0.1884, 0.0262,\n",
      "        0.7284, 0.5345, 0.5344, 0.3204, 0.0190, 0.0162, 0.1799, 0.2654, 0.3207,\n",
      "        0.1799, 0.2269, 0.0756, 0.0171, 0.0140, 0.0221, 0.0167, 0.7760, 0.3570,\n",
      "        0.1964, 0.0155, 0.1429, 0.1544, 0.1394, 0.1461, 0.0132, 0.0213, 0.0000,\n",
      "        0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000])\n",
      "torch.Size([43064, 84])\n",
      "torch.Size([43064, 1])\n"
     ]
    }
   ],
   "source": [
    "# neural networks require tensors, so we need to convert our dataframes to tensors\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    inputs_columns = df.columns[df.columns != 'up']\n",
    "    inputs = torch.from_numpy(df.loc[:, inputs_columns].values.astype('float32'))\n",
    "    targets = torch.from_numpy(df.loc[:, ['up']].values.astype('float32'))\n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "inputs, targets = df_to_tensor(df)\n",
    "print(inputs[0])\n",
    "print(inputs.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(inputs, targets, seq_length):\n",
    "    seq_inputs = []\n",
    "    seq_targets = []\n",
    "    for i in range(len(inputs) - seq_length):\n",
    "        seq_inputs.append(inputs[i:i + seq_length])\n",
    "        seq_targets.append(targets[i + seq_length])\n",
    "    return torch.stack(seq_inputs), torch.stack(seq_targets)\n",
    "\n",
    "sequence_length = 10\n",
    "seq_inputs, seq_targets  = create_sequences(inputs, targets, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a training and validation dataset\n",
    "\n",
    "dataset = TensorDataset(seq_inputs, seq_targets)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch uses dataloaders to load data in batches\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(dataset, batch_size, shuffle = True, num_workers = 0)\n",
    "val_loader = DataLoader(val_dataset, 1, shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# use gpu if avaliable\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_NN(\n",
       "  (lstm): LSTM(84, 256, num_layers=5, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTM_NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# input size is 84 because we have 84 columns in our dataframe\n",
    "# output size is 1 because we are predicting up=1 or down=0\n",
    "input_size = 84\n",
    "output_size = 1\n",
    "hidden_size = 256\n",
    "num_layers = 5\n",
    "model = LSTM_NN(input_size, hidden_size, num_layers, output_size)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for training\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, avg_loss: 0.6930380618783849\n",
      "epoch: 10, avg_loss: 0.6911972507217227\n",
      "epoch: 20, avg_loss: 0.6854921582887864\n",
      "epoch: 30, avg_loss: 0.6600794160859824\n",
      "epoch: 40, avg_loss: 0.5845256952139047\n",
      "epoch: 50, avg_loss: 0.45772125911430495\n",
      "epoch: 60, avg_loss: 0.30911652073704987\n",
      "epoch: 70, avg_loss: 0.18503729112931258\n",
      "epoch: 80, avg_loss: 0.10207750083955787\n",
      "epoch: 90, avg_loss: 0.06333255596987947\n",
      "epoch: 100, avg_loss: 0.043001444001830896\n",
      "epoch: 110, avg_loss: 0.03107854415601968\n",
      "epoch: 120, avg_loss: 0.033595345636069245\n",
      "epoch: 130, avg_loss: 0.028656332946476147\n",
      "epoch: 140, avg_loss: 0.02106245649019642\n",
      "epoch: 150, avg_loss: 0.019677760375018876\n",
      "epoch: 160, avg_loss: 0.0244131539810515\n",
      "epoch: 170, avg_loss: 0.02200047764238301\n",
      "epoch: 180, avg_loss: 0.029434345864426323\n",
      "epoch: 190, avg_loss: 0.017757198776079883\n",
      "epoch: 200, avg_loss: 0.013928080254204065\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "training_losses = []\n",
    "sequence_length = 10\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    epoch_loss = 0\n",
    "    for batch in train_loader:\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.view(-1, sequence_length, input_size)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # forward pass\n",
    "        outputs = model(inputs)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    #average the loss over all batches\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    training_losses.append(avg_loss)\n",
    "    if(epoch % 10 == 0 or epoch == 1):\n",
    "        print(f'epoch: {epoch}, avg_loss: {avg_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.]], device='cuda:0')\n",
      "tensor([[1.]], device='cuda:0')\n",
      "val_loss: 0.006847731642375701, val_acc: 0.9982580420392522\n"
     ]
    }
   ],
   "source": [
    "def validate(model, dataloader, criterion):\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    flag = 0\n",
    "    \n",
    "    with torch.no_grad(): # Disable gradient calculation for efficiency\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.view(-1, sequence_length, input_size)\n",
    "            inputs, targets = inputs.to(device), targets.to(device) # Move data to GPU if available\n",
    "            outputs = model(inputs)\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            loss = criterion(outputs, targets.float()) # BCE loss expects float inputs\n",
    "            val_loss += loss.item() * inputs.size(0) # Track total validation loss\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            if flag == 0:\n",
    "                print(targets)\n",
    "                print(torch.round(outputs))\n",
    "                flag = 1\n",
    "            predicted = torch.round(outputs)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    \n",
    "    # Calculate average validation loss and accuracy\n",
    "    val_loss /= len(dataloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    return val_loss, accuracy\n",
    "\n",
    "val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "print(f'val_loss: {val_loss}, val_acc: {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8384, 0.6218, 0.0964, 0.1332, 0.7610, 0.1500, 0.8000, 0.8250, 0.3453,\n",
      "        0.9183, 0.9200, 0.9199, 0.7466, 0.7152, 0.5881, 0.9176, 0.1422, 0.9272,\n",
      "        0.1510, 0.6481, 0.4280, 0.4814, 0.4289, 0.0998, 0.9250, 1.0000, 0.9338,\n",
      "        0.7940, 0.7269, 0.6243, 0.7610, 0.7181, 0.5339, 0.9604, 0.9982, 0.7262,\n",
      "        0.9215, 0.9080, 0.3292, 0.2287, 0.7729, 0.0916, 0.9254, 0.4240, 0.3633,\n",
      "        0.5953, 0.5943, 0.5943, 0.5881, 0.8577, 0.9200, 0.5049, 0.5539, 0.7208,\n",
      "        0.5049, 0.8912, 0.3345, 0.9084, 0.9210, 0.1042, 0.9145, 0.6438, 0.7618,\n",
      "        0.9248, 0.9222, 0.7811, 0.7888, 0.7927, 0.7887, 0.9190, 0.0442, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000], device='cuda:0')\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "LSTM: Expected input to be 2-D or 3-D but received 1-D tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(inputs[\u001b[39mlen\u001b[39m(inputs)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m----> 7\u001b[0m model(inputs[\u001b[39mlen\u001b[39;49m(inputs)\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\peter\\anaconda3\\envs\\alpaca\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m, in \u001b[0;36mLSTM_NN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m h0 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size)\u001b[39m.\u001b[39mto(x\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m     11\u001b[0m c0 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size)\u001b[39m.\u001b[39mto(x\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m---> 12\u001b[0m out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x, (h0, c0))\n\u001b[0;32m     13\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(out[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :])\n\u001b[0;32m     14\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\peter\\anaconda3\\envs\\alpaca\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\peter\\anaconda3\\envs\\alpaca\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:773\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    771\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    772\u001b[0m     batch_sizes \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 773\u001b[0m     \u001b[39massert\u001b[39;00m (\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLSTM: Expected input to be 2-D or 3-D but received \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39m-D tensor\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    774\u001b[0m     is_batched \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m    775\u001b[0m     batch_dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: LSTM: Expected input to be 2-D or 3-D but received 1-D tensor"
     ]
    }
   ],
   "source": [
    "#not yet working for LSTM model\n",
    "\n",
    "# how will visa do tomorrow? > 0.5 = up, < 0.5 = down\n",
    "inputs, targets = df_to_tensor(df)\n",
    "inputs = inputs.to(device)\n",
    "print(inputs[len(inputs)-1])\n",
    "model(inputs[len(inputs)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [os.path.splitext(os.path.basename(f))[0] for f in os.listdir(\"market_data/merged_data/\") if f.endswith('.csv')]\n",
    "\n",
    "for i, idx in enumerate(idxs):\n",
    "    print(f\"{filenames[i]}: {model(inputs[idx]).item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
